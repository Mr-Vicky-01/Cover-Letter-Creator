{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q -U bitsandbytes==0.42.0\n!pip install -q -U peft==0.8.2\n!pip install -q -U trl==0.7.10\n!pip install -q -U accelerate==0.27.1\n!pip install -q -U transformers==4.38.0","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q -U datasets==2.16.1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:54:25.782502Z","iopub.execute_input":"2024-03-21T09:54:25.783176Z","iopub.status.idle":"2024-03-21T09:54:28.658793Z","shell.execute_reply.started":"2024-03-21T09:54:25.783135Z","shell.execute_reply":"2024-03-21T09:54:28.657862Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# from huggingface_hub import notebook_login\n# notebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:54:28.660571Z","iopub.execute_input":"2024-03-21T09:54:28.661375Z","iopub.status.idle":"2024-03-21T09:54:28.665130Z","shell.execute_reply.started":"2024-03-21T09:54:28.661340Z","shell.execute_reply":"2024-03-21T09:54:28.664270Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"model_id = \"Mr-Vicky-01/Gemma-2B-Finetuined-pythonCode\"\n\n\nmodel = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map={\"\":0})\ntokenizer = AutoTokenizer.from_pretrained(model_id, add_eos_token=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:54:28.666492Z","iopub.execute_input":"2024-03-21T09:54:28.666760Z","iopub.status.idle":"2024-03-21T09:54:33.871008Z","shell.execute_reply.started":"2024-03-21T09:54:28.666738Z","shell.execute_reply":"2024-03-21T09:54:33.870160Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9588faedda774adba9f0ae0447521d6d"}},"metadata":{}}]},{"cell_type":"code","source":"job_title = \"ML Engineer\"\npreferred_qualification = \"3+ years of Deep Learning\"\nhiring_company_name = \"Google\"\nuser_name = \"Vicky\"\npast_working_experience= \"Associate Analyst at zoho for 4 years\"\ncurrent_working_experience = \"Senior Analyst at TCS for 1 year\"\nskilleset= \"Machine Learning, Deep Learning, AI, SQL, NLP\"\nqualification = \"Bachelor of commerce with computer application\"\n\n\nprompt_template = f\"<start_of_turn>user Generate Cover Letter for Role: {job_title}, \\\n Preferred Qualifications: {preferred_qualification}, \\\n Hiring Company: {hiring_company_name}, User Name: {user_name}, \\\n Past Working Experience: {past_working_experience}, Current Working Experience: {current_working_experience}, \\\n Skillsets: {skilleset}, Qualifications: {qualification} <end_of_turn>\\n<start_of_turn>model\"\n\n# prompt_template = \"\"\"\n# <start_of_turn>user based on general question tell me correct answer here are the question\n# What is Artificial Intelligence?\n# <end_of_turn>\\n<start_of_turn>model\n# \"\"\"\n\nprompt = prompt_template\nencodeds = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True)\n\nmodel_inputs = encodeds.to('cuda')\n\n# Increase max_new_tokens if needed\ngenerated_ids = model.generate(**model_inputs, max_new_tokens=250, do_sample=True, pad_token_id=tokenizer.eos_token_id)\ndecoded = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\nprint(decoded)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"ShashiVish/cover-letter-dataset\")\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:54:33.873415Z","iopub.execute_input":"2024-03-21T09:54:33.874280Z","iopub.status.idle":"2024-03-21T09:54:37.418796Z","shell.execute_reply.started":"2024-03-21T09:54:33.874243Z","shell.execute_reply":"2024-03-21T09:54:37.417587Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Job Title', 'Preferred Qualifications', 'Hiring Company', 'Applicant Name', 'Past Working Experience', 'Current Working Experience', 'Skillsets', 'Qualifications', 'Cover Letter'],\n        num_rows: 813\n    })\n    test: Dataset({\n        features: ['Job Title', 'Preferred Qualifications', 'Hiring Company', 'Applicant Name', 'Past Working Experience', 'Current Working Experience', 'Skillsets', 'Qualifications', 'Cover Letter'],\n        num_rows: 349\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"from datasets import concatenate_datasets, DatasetDict\n\nsummary_train = concatenate_datasets([dataset['train'],dataset['test']])\n\nraw_datasets = DatasetDict()\nraw_datasets[\"train\"] = summary_train","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:54:37.420450Z","iopub.execute_input":"2024-03-21T09:54:37.421756Z","iopub.status.idle":"2024-03-21T09:54:37.436509Z","shell.execute_reply.started":"2024-03-21T09:54:37.421709Z","shell.execute_reply":"2024-03-21T09:54:37.435403Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"raw_datasets[\"train\"]","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:54:37.437792Z","iopub.execute_input":"2024-03-21T09:54:37.438207Z","iopub.status.idle":"2024-03-21T09:54:37.446085Z","shell.execute_reply.started":"2024-03-21T09:54:37.438169Z","shell.execute_reply":"2024-03-21T09:54:37.445161Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['Job Title', 'Preferred Qualifications', 'Hiring Company', 'Applicant Name', 'Past Working Experience', 'Current Working Experience', 'Skillsets', 'Qualifications', 'Cover Letter'],\n    num_rows: 1162\n})"},"metadata":{}}]},{"cell_type":"code","source":"def generate_prompt(data_point):\n    \"\"\"Generate input text based on a prompt, task instruction, (context info), and answer.\n\n    :param data_point: dict: Data point\n    :return: dict: Data point with the added \"prompt\" field\n    \"\"\"\n    \n    prompt_text = f\"\"\"<start_of_turn>user Generate Cover Letter for Role: {data_point['Job Title']}, \\\n                 Preferred Qualifications: {data_point['Preferred Qualifications']}, \\\n                 Hiring Company: {data_point['Hiring Company']}, User Name: {data_point['Applicant Name']}, \\\n                 Past Working Experience: {data_point['Past Working Experience']}, Current Working Experience: {data_point['Current Working Experience']}, \\\n                 Skillsets: {data_point['Skillsets']}, Qualifications: {data_point['Qualifications']} <end_of_turn>\\n<start_of_turn>model: {data_point[\"Cover Letter\"]}\"\"\"\n    data_point[\"prompt\"] = prompt_text\n    return data_point\n\n# Add the \"prompt\" column to the dataset\ndataset = raw_datasets[\"train\"].map(generate_prompt)\n\n# Print the updated dataset\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:54:37.447237Z","iopub.execute_input":"2024-03-21T09:54:37.447496Z","iopub.status.idle":"2024-03-21T09:54:37.461055Z","shell.execute_reply.started":"2024-03-21T09:54:37.447469Z","shell.execute_reply":"2024-03-21T09:54:37.460260Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['Job Title', 'Preferred Qualifications', 'Hiring Company', 'Applicant Name', 'Past Working Experience', 'Current Working Experience', 'Skillsets', 'Qualifications', 'Cover Letter', 'prompt'],\n    num_rows: 1162\n})"},"metadata":{}}]},{"cell_type":"code","source":"print(dataset[\"prompt\"][10])","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:54:37.463546Z","iopub.execute_input":"2024-03-21T09:54:37.463791Z","iopub.status.idle":"2024-03-21T09:54:37.472628Z","shell.execute_reply.started":"2024-03-21T09:54:37.463770Z","shell.execute_reply":"2024-03-21T09:54:37.471656Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"<start_of_turn>user Generate Cover Letter for Role:  Data Scientist,                  Preferred Qualifications: 5-10 years of experience in data analysis.\nExperience in anti-money laundering/terrorist financing activities.\nKnowledge of French and English (bilingual).\nBachelor's degree in computer science, mathematics, data science, informatics, operations research, engineering, or a related field.\nExperience with Microsoft Azure and Azure DevOps.,                  Hiring Company: XYZ Corporation, User Name: John Smith,                  Past Working Experience: Data Analyst at ABC Company, Current Working Experience: Data Scientist at DEF Company,                  Skillsets: Python, SQL, SAS, Power BI, TensorFlow, data analysis, reporting design, anti-money laundering, French and English language proficiency, Microsoft Azure., Qualifications: Bachelor's degree in computer science. <end_of_turn>\n<start_of_turn>model: Dear Hiring Manager,\n\nI am writing to express my interest in the Data Scientist position at XYZ Corporation. With my strong background in data analysis, proficiency in various tools and technologies, and experience in anti-money laundering activities, I believe I would be a valuable asset to your team.\n\nIn my current role as a Data Scientist at DEF Company, I have successfully developed filter optimization algorithms to enforce international sanctions and conducted data analysis for reporting design and implementation. I have also participated in client engagements and internal projects, producing insightful analyses of various data sources.\n\nWith a Bachelor's degree in computer science and 5 years of experience in data analysis, I have a solid foundation in the field. My proficiency in Python, SQL, SAS, Power BI, and TensorFlow, along with my knowledge of French and English, make me well-equipped to handle the responsibilities of this role.\n\nI am excited about the opportunity to contribute to XYZ Corporation's mission of providing trust through assurance and helping clients grow, transform, and operate. I am confident that my technical skills, problem-solving abilities, and strong attention to detail would make me a valuable addition to your team.\n\nThank you for considering my application. I look forward to the opportunity to discuss how my skills and qualifications align with the requirements of the Data Scientist position.\n\nSincerely,\nJohn Smith\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset = dataset.shuffle(seed=1234)  # Shuffle dataset here\ndataset = dataset.map(lambda samples: tokenizer(samples[\"prompt\"]), batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:54:37.473665Z","iopub.execute_input":"2024-03-21T09:54:37.473922Z","iopub.status.idle":"2024-03-21T09:54:37.925265Z","shell.execute_reply.started":"2024-03-21T09:54:37.473900Z","shell.execute_reply":"2024-03-21T09:54:37.924260Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:54:37.926555Z","iopub.execute_input":"2024-03-21T09:54:37.926920Z","iopub.status.idle":"2024-03-21T09:54:37.933216Z","shell.execute_reply.started":"2024-03-21T09:54:37.926888Z","shell.execute_reply":"2024-03-21T09:54:37.932161Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['Job Title', 'Preferred Qualifications', 'Hiring Company', 'Applicant Name', 'Past Working Experience', 'Current Working Experience', 'Skillsets', 'Qualifications', 'Cover Letter', 'prompt', 'input_ids', 'attention_mask'],\n    num_rows: 1162\n})"},"metadata":{}}]},{"cell_type":"code","source":"# dataset = dataset.train_test_split(test_size=0.1)\n# train_data = dataset[\"train\"]\n# test_data = dataset[\"test\"]","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:54:37.934394Z","iopub.execute_input":"2024-03-21T09:54:37.934664Z","iopub.status.idle":"2024-03-21T09:54:37.942550Z","shell.execute_reply.started":"2024-03-21T09:54:37.934642Z","shell.execute_reply":"2024-03-21T09:54:37.941633Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\nmodel.gradient_checkpointing_enable()\nmodel = prepare_model_for_kbit_training(model)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:54:37.943510Z","iopub.execute_input":"2024-03-21T09:54:37.943760Z","iopub.status.idle":"2024-03-21T09:54:38.002040Z","shell.execute_reply.started":"2024-03-21T09:54:37.943738Z","shell.execute_reply":"2024-03-21T09:54:38.001156Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import bitsandbytes as bnb\ndef find_all_linear_names(model):\n  cls = bnb.nn.Linear4bit #if args.bits == 4 else (bnb.nn.Linear8bitLt if args.bits == 8 else torch.nn.Linear)\n  lora_module_names = set()\n  for name, module in model.named_modules():\n    if isinstance(module, cls):\n      names = name.split('.')\n      lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n    if 'lm_head' in lora_module_names: # needed for 16-bit\n      lora_module_names.remove('lm_head')\n  return list(lora_module_names)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:54:38.037183Z","iopub.execute_input":"2024-03-21T09:54:38.037726Z","iopub.status.idle":"2024-03-21T09:54:38.043943Z","shell.execute_reply.started":"2024-03-21T09:54:38.037694Z","shell.execute_reply":"2024-03-21T09:54:38.042995Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"modules = find_all_linear_names(model)\nprint(modules)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:54:40.332339Z","iopub.execute_input":"2024-03-21T09:54:40.333207Z","iopub.status.idle":"2024-03-21T09:54:40.338755Z","shell.execute_reply.started":"2024-03-21T09:54:40.333177Z","shell.execute_reply":"2024-03-21T09:54:40.337834Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"['up_proj', 'gate_proj', 'q_proj', 'v_proj', 'down_proj', 'o_proj', 'k_proj']\n","output_type":"stream"}]},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model\n\nlora_config = LoraConfig(\n    r=128,\n    lora_alpha=32,\n    target_modules=modules,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)\n\nmodel = get_peft_model(model, lora_config)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:54:40.696993Z","iopub.execute_input":"2024-03-21T09:54:40.697365Z","iopub.status.idle":"2024-03-21T09:54:42.904724Z","shell.execute_reply.started":"2024-03-21T09:54:40.697337Z","shell.execute_reply":"2024-03-21T09:54:42.903859Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"trainable, total = model.get_nb_trainable_parameters()\nprint(f\"Trainable: {trainable} | total: {total} | Percentage: {trainable/total*100:.4f}%\")","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:54:42.906534Z","iopub.execute_input":"2024-03-21T09:54:42.906895Z","iopub.status.idle":"2024-03-21T09:54:42.918421Z","shell.execute_reply.started":"2024-03-21T09:54:42.906862Z","shell.execute_reply":"2024-03-21T09:54:42.917503Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Trainable: 156893184 | total: 2663065600 | Percentage: 5.8915%\n","output_type":"stream"}]},{"cell_type":"code","source":"import transformers\nimport torch\nfrom trl import SFTTrainer\n\ntokenizer.pad_token = tokenizer.eos_token\ntorch.cuda.empty_cache()\n\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=dataset,\n    dataset_text_field=\"prompt\",\n    peft_config=lora_config,\n    args=transformers.TrainingArguments(\n        per_device_train_batch_size=1,  # Increased batch size\n        gradient_accumulation_steps=2,  # Adjusted accumulation steps\n        warmup_steps=500,  # Increased warm-up steps\n        num_train_epochs=1,  # Increased epochs\n        max_steps=500,  # Increased maximum steps\n        learning_rate=1e-4,  # Decreased learning rate\n        logging_steps=10,  # Adjusted logging frequency\n        output_dir=\"python_model\",  # Change the output directory\n        optim=\"adamw_hf\",  # Changed optimizer\n        save_strategy=\"epoch\",\n    ),\n    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:55:00.787775Z","iopub.execute_input":"2024-03-21T09:55:00.788965Z","iopub.status.idle":"2024-03-21T09:55:05.713494Z","shell.execute_reply.started":"2024-03-21T09:55:00.788922Z","shell.execute_reply":"2024-03-21T09:55:05.712489Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"2024-03-21 09:55:01.685676: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-21 09:55:01.685729: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-21 09:55:01.687029: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:223: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:290: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:55:05.714993Z","iopub.execute_input":"2024-03-21T09:55:05.715322Z","iopub.status.idle":"2024-03-21T10:06:17.539900Z","shell.execute_reply.started":"2024-03-21T09:55:05.715293Z","shell.execute_reply":"2024-03-21T10:06:17.538396Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvickyvijay069\u001b[0m (\u001b[33mvicky12\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240321_095508-9mehoevq</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/vicky12/huggingface/runs/9mehoevq' target=\"_blank\">upbeat-dragon-18</a></strong> to <a href='https://wandb.ai/vicky12/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/vicky12/huggingface' target=\"_blank\">https://wandb.ai/vicky12/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/vicky12/huggingface/runs/9mehoevq' target=\"_blank\">https://wandb.ai/vicky12/huggingface/runs/9mehoevq</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='294' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [294/500 10:32 < 07:25, 0.46 it/s, Epoch 0.50/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>1.828800</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.904300</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.747700</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.754100</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.596700</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.507300</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>1.374800</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>1.394100</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>1.116000</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>1.034100</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>0.919500</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.788400</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>0.849200</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.832500</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.704600</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.716500</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>0.876300</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.868900</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>0.692100</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.691800</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>0.664200</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>0.633900</td>\n    </tr>\n    <tr>\n      <td>230</td>\n      <td>0.747700</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>0.728500</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.677200</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>0.741100</td>\n    </tr>\n    <tr>\n      <td>270</td>\n      <td>0.689300</td>\n    </tr>\n    <tr>\n      <td>280</td>\n      <td>0.805700</td>\n    </tr>\n    <tr>\n      <td>290</td>\n      <td>0.581800</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"\nKeyboardInterrupt\n\n","output_type":"stream"}]},{"cell_type":"code","source":"new_model = \"gemma-finetuned-python_code\"\ntrainer.model.save_pretrained(new_model)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T10:08:22.381769Z","iopub.execute_input":"2024-03-21T10:08:22.383083Z","iopub.status.idle":"2024-03-21T10:08:23.767742Z","shell.execute_reply.started":"2024-03-21T10:08:22.383044Z","shell.execute_reply":"2024-03-21T10:08:23.766700Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"base_model = AutoModelForCausalLM.from_pretrained(\n    model_id,\n    low_cpu_mem_usage=True,\n    return_dict=True,\n    torch_dtype=torch.float16,\n    device_map={\"\": 0},\n)\nmerged_model= PeftModel.from_pretrained(base_model, new_model)\nmerged_model= merged_model.merge_and_unload()\n\n# Save the merged model\nmerged_model.save_pretrained(\"merged_model_new\",safe_serialization=True)\ntokenizer.save_pretrained(\"merged_model_new_tokenizer\")\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"right\"","metadata":{"execution":{"iopub.status.busy":"2024-03-21T10:08:25.366398Z","iopub.execute_input":"2024-03-21T10:08:25.367284Z","iopub.status.idle":"2024-03-21T10:08:48.053760Z","shell.execute_reply.started":"2024-03-21T10:08:25.367237Z","shell.execute_reply":"2024-03-21T10:08:48.052538Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdcc4eda359540b4bd6af3a51ac255b8"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\n\nmerged_model = AutoModelForCausalLM.from_pretrained(\"/kaggle/working/merged_model_new\")\ntokenizer = AutoTokenizer.from_pretrained(\"/kaggle/working/merged_model_new_tokenizer\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"job_title = \"ML Engineer\"\npreferred_qualification = \"strong AI realted skills\"\nhiring_company_name = \"Google\"\nuser_name = \"Vicky\"\npast_working_experience= \"N/A\"\ncurrent_working_experience = \"Fresher\"\nskilleset= \"Machine Learning, Deep Learning, AI, SQL, NLP\"\nqualification = \"Bachelor of commerce with computer application\"\n\n\nprompt_template = f\"<start_of_turn>user Generate Cover Letter for Role: {job_title}, \\\n Preferred Qualifications: {preferred_qualification}, \\\n Hiring Company: {hiring_company_name}, User Name: {user_name}, \\\n Past Working Experience: {past_working_experience}, Current Working Experience: {current_working_experience}, \\\n Skillsets: {skilleset}, Qualifications: {qualification} <end_of_turn>\\n<start_of_turn>model\"\n\nprompt = prompt_template\nencodeds = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True).input_ids\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmerged_model.to(device)\ninputs = encodeds.to(device)\n\n\n# Increase max_new_tokens if needed\ngenerated_ids = merged_model.generate(inputs, max_new_tokens=250, do_sample=False, pad_token_id=tokenizer.eos_token_id)\nans = ''\nfor i in tokenizer.decode(generated_ids[0], skip_special_tokens=True).split('<end_of_turn>')[:2]:\n    ans += i\n\n# Extract only the model's answer\nmodel_answer = ans.split(\"model\")[1].strip()\nprint(model_answer)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T10:15:49.751409Z","iopub.execute_input":"2024-03-21T10:15:49.752242Z","iopub.status.idle":"2024-03-21T10:15:57.353998Z","shell.execute_reply.started":"2024-03-21T10:15:49.752209Z","shell.execute_reply":"2024-03-21T10:15:57.352965Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","output_type":"stream"},{"name":"stdout","text":"I am a recent graduate with a Bachelor of Commerce with Computer Application. I have strong AI related skills and am eager to apply them at Google. I am currently a fresher and have no previous working experience. I am confident that my skills and experience will make me a valuable asset to your team. I am looking forward to the opportunity to contribute to your success.\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset['Cover Letter'][0]","metadata":{"execution":{"iopub.status.busy":"2024-03-21T10:13:57.326325Z","iopub.execute_input":"2024-03-21T10:13:57.327062Z","iopub.status.idle":"2024-03-21T10:13:57.339198Z","shell.execute_reply.started":"2024-03-21T10:13:57.327028Z","shell.execute_reply":"2024-03-21T10:13:57.337676Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"'With a strong background in customer support and a knack for problem-solving, I am confident in my ability to significantly contribute to Innovation Inc. In my previous roles at XYZ Company and ABC Company, I have consistently provided high-quality support to customers, resolving issues efficiently and maintaining a high level of customer satisfaction. I am eager to bring my strong commitment to quality support to your team.'"},"metadata":{}}]},{"cell_type":"code","source":"dataset[\"prompt\"][0]","metadata":{"execution":{"iopub.status.busy":"2024-03-21T10:12:00.101100Z","iopub.execute_input":"2024-03-21T10:12:00.102050Z","iopub.status.idle":"2024-03-21T10:12:00.114833Z","shell.execute_reply.started":"2024-03-21T10:12:00.102018Z","shell.execute_reply":"2024-03-21T10:12:00.113699Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"'<start_of_turn>user Generate Cover Letter for Role: Senior Support Engineer,                  Preferred Qualifications: 5+ years experience in customer support, knowledge of SQL,                  Hiring Company: Innovation Inc., User Name: Jane Smith,                  Past Working Experience: Customer Support Representative at XYZ Company for 3 years, Current Working Experience: Senior Customer Support Representative at ABC Company for 3 years,                  Skillsets: Customer Support, SQL, Problem-solving, Qualifications: B.A. in Business Administration <end_of_turn>\\n<start_of_turn>model: With a strong background in customer support and a knack for problem-solving, I am confident in my ability to significantly contribute to Innovation Inc. In my previous roles at XYZ Company and ABC Company, I have consistently provided high-quality support to customers, resolving issues efficiently and maintaining a high level of customer satisfaction. I am eager to bring my strong commitment to quality support to your team.'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}